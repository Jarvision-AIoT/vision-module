from flask import Flask, render_template, request, jsonify
import cv2
import numpy as np
import base64
import mediapipe as mp
import math

app = Flask(__name__)

# Mediapipe ì„¤ì •
mp_hands = mp.solutions.hands # ì† ì¸ì‹ ëª¨ë¸ ìƒì„±
hands = mp_hands.Hands(
    static_image_mode=True,
    max_num_hands=2,  # âœ… ìµœëŒ€ 2ê°œì˜ ì†ê¹Œì§€ ì¸ì‹í•˜ë„ë¡ ì„¤ì •
    min_detection_confidence=0.5
)
mp_drawing = mp.solutions.drawing_utils # ì† ê´€ì ˆì— ì‹œê°ì ìœ¼ë¡œ ì„ ì„ ì—°ê²°í•´ì£¼ëŠ” Util

def angle_between(v1, v2):
    """
    ë‘ 2D ë²¡í„° ì‚¬ì´ì˜ ê°ë„(ë¼ë””ì•ˆ ë‹¨ìœ„)ë¥¼ ë°˜í™˜
    """
    v1 = np.array(v1)
    v2 = np.array(v2)
    unit_v1 = v1 / np.linalg.norm(v1)
    unit_v2 = v2 / np.linalg.norm(v2)
    dot_product = np.clip(np.dot(unit_v1, unit_v2), -1.0, 1.0)
    angle = np.arccos(dot_product)  # ë¼ë””ì•ˆ
    return angle



def is_thumb_extended(hand):
    """
    ì—„ì§€ê°€ í´ì¡ŒëŠ”ì§€ êµ½í˜€ì¡ŒëŠ”ì§€ë¥¼ ê°ë„ë¡œ íŒë‹¨
    - 0~30ë„: í´ì§
    - 40ë„ ì´ìƒ: êµ½í˜€ì§
    """
    wrist = hand.landmark[0]
    thumb_mcp = hand.landmark[2]
    thumb_tip = hand.landmark[4]

    v1 = [thumb_mcp.x - wrist.x, thumb_mcp.y - wrist.y]
    v2 = [thumb_tip.x - thumb_mcp.x, thumb_tip.y - thumb_mcp.y]

    angle = angle_between(v1, v2) * (180 / math.pi)  # ë¼ë””ì•ˆ â†’ ë„

    return angle < 40  # ê¸°ì¤€ ê°ë„ (ê²½í—˜ì ìœ¼ë¡œ 30~40ë„ ì¶”ì²œ)


def get_finger_status(hand, handedness = 'Right'):
    """
    ì†ê°€ë½ì´ í´ì ¸ ìˆëŠ”ì§€ ì ‘í˜€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜

    Input:
        hand
    Returns:
        fingers_status[i, i, i, i, i](list)
        - 1: í´ì ¸ ìˆì„ ë•Œ
        - 0: ì ‘í˜€ ìˆì„ ë•Œ
    """
    # ì˜¤ë¥¸ì† ê¸°ì¤€
    fingers = []

    # ì—„ì§€:
  #  if handedness == 'Right': # ì˜¤ë¥¸ì†
  #      if hand.landmark[4].x < hand.landmark[3].x:
  #          fingers.append(1)
  #      else:
  #          fingers.append(0)
  #  else:  # ì™¼ì†
  #      if hand.landmark[4].x > hand.landmark[3].x:
  #          fingers.append(1)
  #      else:
  #          fingers.append(0)
  
    if is_thumb_extended(hand):
        fingers.append(1)
    else:
        fingers.append(0)


    # ë‚˜ë¨¸ì§€ ì†ê°€ë½ (ì˜¤ë¥¸ì† ê¸°ì¤€):
    # ê° ì†ê°€ë½ì˜ íŒ (8, 12, 16, 20)ì´ PIP (6, 10, 14, 18) ìœ„ì— ìˆìœ¼ë©´ í¼ì³ì§„ ìƒíƒœ
    tips = [8, 12, 16, 20]
    pip_joints = [6, 10, 14, 18]
    for tip, pip in zip(tips, pip_joints):
        if hand.landmark[tip].y < hand.landmark[pip].y:
            fingers.append(1)
        else:
            fingers.append(0)

    return fingers

def recognize_gesture(fingers_status, hand=None, image_width=None, image_height=None):

    # OK ì‚¬ì¸: ì—„ì§€(4ë²ˆ)ì™€ ê²€ì§€(8ë²ˆ) ë ì‚¬ì´ ê±°ë¦¬ ê¸°ì¤€
    if hand and image_width and image_height:
        thumb_tip = hand.landmark[4]
        index_tip = hand.landmark[8]

        dx = (thumb_tip.x - index_tip.x) * image_width
        dy = (thumb_tip.y - index_tip.y) * image_height
        distance = (dx**2 + dy**2)**0.5

        # ê±°ë¦¬ê°€ 30 pixel ì´í•˜ë©´ OK Sign
        if distance < 30:
            return 'ok_sign' #ğŸ‘Œ

    if fingers_status == [0, 0, 0, 0, 0]:
        return 'fist'       #âœŠ
    elif fingers_status == [0, 1, 0, 0, 0]:
        return 'point'      #â˜ï¸
    elif fingers_status == [1, 1, 1, 1, 1]:
        return 'open'       #âœ‹
    elif fingers_status == [0, 1, 1, 0, 0]:
        return 'peace'      #âœŒï¸
    elif fingers_status == [1, 1, 0, 0, 0]:
        return 'standby'    #ğŸ‘†
    elif fingers_status == [1, 0, 0, 0, 0]:
        return 'thumbs_up'  #ğŸ‘
    elif fingers_status == [1, 0, 0, 0, 1]:
        return 'rock'       #ğŸ¤™
    elif fingers_status == [1, 1, 0, 0, 1]:
        return 'love_u'     #ğŸ¤Ÿ

    return 'none'

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    data = request.get_json()
    img_data = base64.b64decode(data['image'].split(',')[1])
    np_img = np.frombuffer(img_data, np.uint8)
    frame = cv2.imdecode(np_img, cv2.IMREAD_COLOR)

    # ì¢Œìš° ë°˜ì „ ë³µì› ë° Video Frameì„ Mediapipe Pipelineì— ì „ë‹¬
    frame = cv2.flip(frame, 1)
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(frame_rgb)

    # ì œìŠ¤ì²˜ì™€ ì†ê°€ë½ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    gestures = []
    fingers_list = []

    if result.multi_hand_landmarks and result.multi_handedness:
        for idx, (hand_landmark, hand_handedness) in enumerate(zip(result.multi_hand_landmarks, result.multi_handedness)):
            handedness_label = hand_handedness.classification[0].label  # 'Left' or 'Right'

            fingers = get_finger_status(hand_landmark, handedness_label)
            gesture = recognize_gesture(
                fingers,
                hand=hand_landmark,
                image_width=frame.shape[1],
                image_height=frame.shape[0]
            )

            gestures.append({
                'hand': handedness_label,
                'gesture': gesture
            })

            fingers_list.append({
                'hand': handedness_label,
                'fingers': fingers
            })

            print(f"{handedness_label} hand: {gesture}, fingers: {fingers}")

    return jsonify({
        'gestures': gestures,      # [{'hand': 'Right', 'gesture': 'peace'}, ...]
        'fingers_list': fingers_list  # [{'hand': 'Left', 'fingers': [1,0,0,0,0]}, ...]
    })

if __name__ == '__main__':
    app.run(debug=True)