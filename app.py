from flask import Flask, render_template, request, jsonify
import cv2
import numpy as np
import base64
import mediapipe as mp

app = Flask(__name__)

# Mediapipe ì„¤ì •
mp_hands = mp.solutions.hands # ì† ì¸ì‹ ëª¨ë¸ ìƒì„±
hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils # ì† ê´€ì ˆì— ì‹œê°ì ìœ¼ë¡œ ì„ ì„ ì—°ê²°í•´ì£¼ëŠ” Util

def get_finger_status(hand):
    """
    ì†ê°€ë½ì´ í´ì ¸ ìˆëŠ”ì§€ ì ‘í˜€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜

    Input:
        hand
    Returns:
        fingers_status[i, i, i, i, i](list)
        - 1: í´ì ¸ ìˆì„ ë•Œ
        - 0: ì ‘í˜€ ìˆì„ ë•Œ
    """
    # ì˜¤ë¥¸ì† ê¸°ì¤€
    fingers = []

    # ì—„ì§€ (ì˜¤ë¥¸ì† ê¸°ì¤€):
    # ëœë“œë§ˆí¬ 4ê°€ ëœë“œë§ˆí¬ 3ì˜ ì™¼ìª½ì— ìˆìœ¼ë©´ í¼ì³ì§„ ìƒíƒœ
    if hand.landmark[4].x < hand.landmark[3].x:
        fingers.append(1)
    else:
        fingers.append(0)

    # ë‚˜ë¨¸ì§€ ì†ê°€ë½ (ì˜¤ë¥¸ì† ê¸°ì¤€):
    # ê° ì†ê°€ë½ì˜ íŒ (8, 12, 16, 20)ì´ PIP (6, 10, 14, 18) ìœ„ì— ìˆìœ¼ë©´ í¼ì³ì§„ ìƒíƒœ
    tips = [8, 12, 16, 20]
    pip_joints = [6, 10, 14, 18]
    for tip, pip in zip(tips, pip_joints):
        if hand.landmark[tip].y < hand.landmark[pip].y:
            fingers.append(1)
        else:
            fingers.append(0)

    return fingers

def recognize_gesture(fingers_status, hand=None, image_width=None, image_height=None):

    # OK ì‚¬ì¸: ì—„ì§€(4ë²ˆ)ì™€ ê²€ì§€(8ë²ˆ) ë ì‚¬ì´ ê±°ë¦¬ ê¸°ì¤€
    if hand and image_width and image_height:
        thumb_tip = hand.landmark[4]
        index_tip = hand.landmark[8]

        dx = (thumb_tip.x - index_tip.x) * image_width
        dy = (thumb_tip.y - index_tip.y) * image_height
        distance = (dx**2 + dy**2)**0.5

        if distance < 30:
            return 'ok_sign' #ğŸ‘Œ

    if fingers_status == [0, 0, 0, 0, 0]:
        return 'fist'       #âœŠ
    elif fingers_status == [0, 1, 0, 0, 0]:
        return 'point'      #â˜ï¸
    elif fingers_status == [1, 1, 1, 1, 1]:
        return 'open'       #âœ‹
    elif fingers_status == [0, 1, 1, 0, 0]:
        return 'peace'      #âœŒï¸
    elif fingers_status == [1, 1, 0, 0, 0]:
        return 'standby'    #ğŸ‘†
    elif fingers_status == [1, 0, 0, 0, 0]:
        return 'thumbs_up'  #ğŸ‘
    elif fingers_status == [1, 0, 0, 0, 1]:
        return 'rock'       #ğŸ¤™
    elif fingers_status == [1, 1, 0, 0, 1]:
        return 'love_u'     #ğŸ¤Ÿ

    return 'none'

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    data = request.get_json()
    img_data = base64.b64decode(data['image'].split(',')[1])
    np_img = np.frombuffer(img_data, np.uint8)
    frame = cv2.imdecode(np_img, cv2.IMREAD_COLOR)

    # ì¢Œìš° ë°˜ì „ ë³µì›
    frame = cv2.flip(frame, 1)

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(frame_rgb)

    gesture = 'none'
    fingers = []

    if result.multi_hand_landmarks:
        hand_landmark = result.multi_hand_landmarks[0]

        fingers = get_finger_status(result.multi_hand_landmarks[0])
        gesture = recognize_gesture(
            fingers,
            hand=hand_landmark,
            image_width=frame.shape[1],
            image_height=frame.shape[0]
        )

        print(gesture)
        # ì† ëœë“œë§ˆí¬ì™€ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        # mp_drawing.draw_landmarks(frame, result.multi_hand_landmarks, mp_hands.HAND_CONNECTIONS)

    return jsonify({
        'gesture': gesture,
        'fingers': fingers  # fingers = [0, 1, 0, 0, 0] ê°™ì€ ë¦¬ìŠ¤íŠ¸
    })

if __name__ == '__main__':
    app.run(debug=True)